**Disclaimer:** GPT Deep Research was used for generating abstracts

1. **Hyvärinen (2005)** – *Score Matching for Generative Models.* Aapo Hyvärinen’s 2005 paper introduced the **score matching** method, a technique for training probabilistic models by matching the model’s score (the gradient of the log-density) to that of the data distribution[\[1\]](https://jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf#:~:text=Here%2C%20we%20propose%20that%20such,The%20density). This contribution was foundational for diffusion models, as it provides a way to learn complex, unnormalized distributions without needing explicit likelihoods. In essence, score matching allows a model to capture fine-grained details of a data distribution – an idea later used in *score-based diffusion models* where one trains a network to predict the gradient of the data density at various noise levels.

   * **Relation to fluid dynamics:** Though Hyvärinen’s work was general and not about fluids, the concept underpins how modern diffusion models (including those for fluid fields) learn to generate data. For example, when a diffusion model is used as a surrogate for fluid flow, it effectively learns the “score” of high-dimensional flow data, enabling it to sample realistic fluid states.

   * **Links to other works:** Hyvärinen’s idea directly inspired later developments like score-based generative modeling and is explicitly referenced in works such as Holzschuh et al. (2023), who use score matching to solve physics problems. It set the stage for diffusion-based approaches by ensuring models could be trained on complex distributions – a necessary step for simulating turbulent flows with machine learning.

2. **Sohl-Dickstein et al. (2015)** – *Deep Unsupervised Learning via Diffusion (Foundational Diffusion Model).* This work was the first to demonstrate **diffusion probabilistic models** as a viable generative approach[\[2\]](https://arxiv.org/abs/1503.03585#:~:text=achieves%20both%20flexibility%20and%20tractability,reference%20implementation%20of%20the%20algorithm). Sohl-Dickstein and colleagues proposed slowly destroying structure in data through a forward diffusion process (adding noise step by step) and then learning a reverse process to *restore* structure, thus generating new samples from noise[\[2\]](https://arxiv.org/abs/1503.03585#:~:text=achieves%20both%20flexibility%20and%20tractability,reference%20implementation%20of%20the%20algorithm). The main contribution is a method that achieves both high flexibility in modeling data and tractable inference by leveraging principles of non-equilibrium thermodynamics. They showed that by the end of the forward process the data become pure noise, and a neural network can be trained to gradually denoise and recover data – yielding a highly flexible generative model of complex data distributions.

   * **Relation to fluid dynamics:** This framework underlies *all* modern diffusion models. In the context of fluid simulations, the same idea is applied – one can start from random noise and iteratively refine it (according to a learned model) to produce a physically plausible flow field. Essentially, Sohl-Dickstein et al.’s method assures us that diffusion-based generation can capture intricate distributions like those of turbulent flows, given enough steps.

   * **Links to other works:** This paper laid the groundwork that later diffusion models (e.g. Ho et al. 2020, Dhariwal & Nichol 2021\) built upon. Every diffusion model cited (image, video, text, or fluids) inherits this concept of forward noising and reverse denoising. The approach demonstrated by Sohl-Dickstein et al. is directly cited in the fluid dynamics diffusion papers (e.g. Lienen et al. 2024\) as a starting point for adapting diffusion to new domains.

3. **Dhariwal and Nichol (2021)** – *Diffusion Models Beat GANs on Image Synthesis.* Dhariwal & Nichol showed that diffusion models can achieve **state-of-the-art image generation quality**, surpassing GANs for the first time[\[3\]](https://arxiv.org/abs/2105.05233#:~:text=,guidance%20combines%20well%20with%20upsampling). The paper’s main contributions were improvements to the diffusion model architecture and sampling techniques that dramatically improved visual fidelity. They introduced optimizations such as a better U-Net backbone (found via extensive ablations) and **classifier guidance**, which allows trading diversity for accuracy by using a classifier’s gradients during sampling[\[4\]](https://arxiv.org/abs/2105.05233#:~:text=superior%20to%20the%20current%20state,guidance%20combines%20well%20with%20upsampling). As a result, their diffusion models achieved record-low FID scores on ImageNet and could even match GAN results with as few as 25 denoising steps (much faster than the typical 1000 steps)[\[5\]](https://arxiv.org/abs/2105.05233#:~:text=of%20ablations,at%20%2013%20this%20https). 

   * **Relation to fluid dynamics:** This work is a proof of concept that diffusion models are powerful and can be made efficient. For researchers using diffusion models as fluid surrogates, the lesson is twofold: (a) diffusion models have the capacity to model very complex, high-dimensional distributions (like turbulent flow fields) with high fidelity, and (b) sampling speed can be improved (e.g., through guided sampling or model distillation) without completely sacrificing accuracy. In other words, the success of Dhariwal & Nichol (2021) motivates attempts to narrow the gap between diffusion models and faster methods – exactly the goal in fluid simulations where long rollout times are a concern.

   * **Links to other works:** Many later works, including those in scientific domains, cite this paper as it cemented diffusion models’ reputation. For instance, the idea of using *guidance* (whether by a classifier or other means) to improve sample quality appears in some fluid applications as well, and the focus on reducing the number of sampling steps foreshadows methods like progressive distillation or the truncated sampling strategies explored in 2024–2025 fluid papers.

4. **Wang et al. (2022 – Semantic Image Synthesis via Diffusion)** – *Using Diffusion Models for Conditional Image Generation.* Wang and colleagues extended diffusion models to the task of **semantic image synthesis**, where the goal is to generate realistic images from input segmentation maps or layouts. The main contribution was showing that a diffusion model can be conditioned on high-level semantic information to create detailed outputs that obey the provided structure. They likely implemented this by feeding the semantic map into the model (e.g., as additional channels or through cross-attention) so that at each denoising step the model is guided to produce content aligned with the input label map. This allowed the diffusion process to fill in realistic textures and objects while respecting boundaries and classes indicated by the segmentation.

   * **Relation to fluid dynamics:** In fluid simulations, we often have conditions (like boundary shapes, initial velocities, or parameters such as Reynolds number) that play a role similar to a “semantic layout.” Wang et al.’s work is an existence proof that diffusion models handle *conditional generation* well: just as one can generate an image given a layout, one could generate a flow given boundary conditions or geometry. In fact, later fluid diffusion studies (e.g., Lienen et al. 2024\) do something analogous by conditioning on obstacle shapes or other parameters when generating flow fields. The similarity is that both require the generative model to incorporate certain constraints, and diffusion models prove adept at this by design (since conditioning information can be injected at each timestep).

   * **Links to other works:** This paper sits alongside other conditional diffusion advancements (like image inpainting and super-resolution). It shares inspiration with Lugmayr et al. (2022, *RePaint*), in that both use diffusion models to **guide generation with partial information** – Wang et al. use a semantic guide, while RePaint uses known pixels as a guide. In the bigger picture, both suggest that diffusion models are highly modular and can be steered by various inputs, a property leveraged heavily in physics-informed diffusion models and conditional simulators.

5. **Lugmayr et al. (2022 – RePaint)** – *Diffusion-based Image Inpainting.* Andreas Lugmayr and colleagues introduced **RePaint**, an algorithm that applies diffusion models to image inpainting (filling in missing regions of an image)[\[6\]](https://www.researchgate.net/publication/358143708_RePaint_Inpainting_using_Denoising_Diffusion_Probabilistic_Models#:~:text=,). The core idea is to use a **pre-trained unconditional diffusion model** as a prior and modify the reverse diffusion sampling process to respect known pixels. Concretely, at each denoising step RePaint replaces the generated content in the known (non-missing) regions with the original pixels of the image, before continuing to the next step[\[6\]](https://www.researchgate.net/publication/358143708_RePaint_Inpainting_using_Denoising_Diffusion_Probabilistic_Models#:~:text=,). This clever stepwise conditioning ensures that the final output matches the given pixels exactly while the model “freely” hallucinates plausible content in the masked areas. The main contribution is achieving high-quality and diverse inpainting results without training a model specifically for inpainting – instead, they reuse a general diffusion model and impose constraints during sampling.

   * **Relation to fluid dynamics:** RePaint demonstrates how diffusion models can solve **inverse problems** or tasks with partial information. In fluid dynamics, one often faces analogous situations: e.g., reconstructing a flow field in regions where data is missing or inferring a flow given some known boundaries or measurements. The RePaint approach suggests one can train a diffusion model on general fluid data and later constrain it with observations to “paint in” the rest of the flow field. Indeed, subsequent works in physics have adopted similar strategies. For example, Lienen et al. (2024) cite using an inpainting-like method to enforce boundary conditions in generative flow simulations (fixing the velocity at wall boundaries while the model fills in the interior flow).

   * **Links to other works:** RePaint is part of a family of diffusion applications that treat generation as an iterative refinement problem with constraints – this includes solver-guided generations in physics (Holzschuh et al. 2023 use a score-based model plus a physics solver, conceptually parallel in combining a prior with constraints). It also shares methodological DNA with Wang et al. (2022) in showing how conditioning can be applied during diffusion. The success of RePaint across varied mask types confirms the **robustness and flexibility** of diffusion sampling, a reassuring fact for those looking to apply similar techniques to the irregular “masks” or partial data scenarios in fluid problems.

6. **Ho et al. (2022 – Video Diffusion Models)** – *Extending Diffusion to the Video Domain.* Jonathan Ho and collaborators proposed one of the first **diffusion models for video generation**, addressing the additional challenge of maintaining temporal coherence across frames[\[7\]](https://arxiv.org/abs/2204.03458#:~:text=,We%20present%20the). Their model is a natural extension of image-based diffusion: it uses a 3D U-Net–style architecture (space *x* time) to denoise video data, and it can even be trained on static images \+ short videos together to improve stability[\[8\]](https://arxiv.org/abs/2204.03458#:~:text=milestone%20by%20proposing%20a%20diffusion,generation%20task%2C%20as%20well%20as). Key contributions include a **factorized space-time architecture** (to handle the high dimensionality of video) and a technique for generating longer or higher-resolution videos by conditioning on a smaller generated video and diffusing additional frames or pixels (a form of **conditional sampling for extension**)[\[9\]](https://arxiv.org/abs/2204.03458#:~:text=image%20diffusion%20architecture%2C%20and%20it,available%20at%20this%20https%20URL). The paper demonstrated state-of-the-art results in unconditional video generation and competitive results in video prediction and text-conditioned video, proving that diffusion models can learn dynamic processes, not just static images.

   * **Relation to fluid dynamics:** Video diffusion models are highly analogous to diffusion models for fluid **time-series**. A turbulent flow simulation can be thought of as a “video” of velocity and pressure fields evolving over time. Ho et al.’s work suggests that a diffusion model can capture spatio-temporal correlations – ensuring that if frame *t* and *t+1* are physically related, the model generates them consistently. This property is vital for fluid simulations: it’s no use having each frame look realistic in isolation if the sequence as a whole is unphysical. Moreover, the idea of using conditional diffusion to generate longer sequences aligns with how one might simulate a long fluid trajectory by iteratively generating small segments.

   * **Links to other works:** The video diffusion paper inspired fluid modelers to consider diffusion for *trajectory generation*. For instance, Kohl et al. (2024) and Yang & Sommer (2023) adopt an **autoregressive diffusion** approach for simulating many time steps, effectively treating a fluid flow like a video to be generated one frame at a time. The technical solutions from video diffusion (such as factoring the U-Net or using prior generated frames as conditional input for extension) could be adapted to fluid simulations to ensure long-term consistency. In summary, Ho et al. (2022) bridged the gap between static and dynamic generative tasks, providing a template for how to handle temporal correlations – a challenge common to video synthesis and time-dependent physics simulations.

7. **Li et al. (2023)** – *Survey: Diffusion Models for Non-Autoregressive Text Generation.* Yifan Li and colleagues presented a comprehensive survey of how diffusion models are being applied to text generation, specifically focusing on **non-autoregressive (NAR) methods** (where the model generates the whole sequence in parallel rather than token-by-token). The survey outlines the general formulation of diffusion models and then discusses the unique adaptations needed for text, such as working in a discrete token space versus a continuous space[\[10\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=review%20the%20recent%20progress%20in,and%20introduce%20optimization%20techniques%20for)[\[11\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=e.g.%2C%20knowledge%20distillation%20,the%20intermediate%20generated%20results%20conditioned). It covers two main paradigms: (1) **continuous diffusion** in which text is embedded into continuous representations and diffused (as in Diffusion-LM or DiffuSeq), and (2) **discrete diffusion** where noise is defined over tokens directly[\[12\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=generation%20quality%2C%20leading%20to%20an,the%20discrete%20essence%20and%20complex). The authors review key techniques to improve NAR text diffusion, like handling token order ambiguity, accelerating sampling (since long texts would otherwise require many diffusion steps), and incorporating pre-trained language models for better linguistic knowledge[\[13\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=present%20the%20general%20defnition%20of,Our%20survey)[\[14\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=progressively%20convert%20a%20random%20noise,to%20an%20improved%20generation%20ability). The main contribution is organizing and summarizing the recent progress in this nascent field, highlighting that diffusion models have achieved improved text quality compared to previous NAR approaches, though challenges remain in balancing inference speed and accuracy.

   * **Relation to fluid dynamics:** While text generation and fluid simulation seem very different, there is a conceptual parallel: both can involve sequential data generation. Traditional text generators use autoregression (much like time-stepping in simulations), whereas diffusion offers a way to generate an entire sequence “all at once” with refinement. In fluid terms, this is akin to generating a whole flow field or trajectory in a single go rather than marching step by step. In fact, Lienen et al. (2024) took a non-autoregressive approach to flow generation – learning the distribution of steady-state 3D flows and sampling from it directly, which is analogous to generating a whole text in one pass. The survey by Li et al. underlines strategies (like *iterative refinement* of a draft output) that are also seen in fluid diffusion models (e.g., PDE-Refiner by Lippe et al. 2023 uses iterative refinement for each time step).

   * **Links to other works:** This survey references foundational diffusion works (Sohl-Dickstein 2015; Ho et al. 2020\) and adapts their lessons to text. The notion of *balancing inference latency with quality* is a common theme with the fluid diffusion community: for text, methods like knowledge distillation or improved samplers are explored[\[14\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=progressively%20convert%20a%20random%20noise,to%20an%20improved%20generation%20ability), while for fluids, recent works experiment with truncated processes or flow matching (as in Liu & Thuerey 2024\) to speed up generation. Overall, Li et al.’s survey highlights the **generality** of diffusion models – from images to text to scientific data – and cross-pollinates ideas that could inspire techniques in physics (e.g., how to handle discrete events or constraints in a diffusion process, which might translate to handling phase changes or shocks in fluids via diffusion modeling).

8. **Holzschuh et al. (2023)** – *Solving Inverse Physics Problems with Score Matching.* Benjamin Holzschuh and colleagues applied diffusion-model techniques to **inverse problems in physics**, using score matching as the learning objective[\[15\]](https://arxiv.org/abs/2301.10250#:~:text=combining%20an%20approximate%20inverse%20physics,contrast%20to%20other%20learned%20inverse). The paper addresses scenarios where one observes the outcome of a physical process and wants to infer the input or earlier state (for example, determining initial conditions of a fluid flow from later observations, or recovering parameters from measured data). The authors propose an approach that *integrates a physics simulator with a learned model*: they use a coarse “inverse” physics solver to take a guess at the solution, then a learned **correction network** to refine this guess. Crucially, they show that if this correction network is trained with a one-step objective (correcting the simulator’s output for a single time-step inversion), it is mathematically equivalent to training via **denoising score matching** on the trajectory space[\[15\]](https://arxiv.org/abs/2301.10250#:~:text=combining%20an%20approximate%20inverse%20physics,contrast%20to%20other%20learned%20inverse). In other words, the network learns the gradient of the log-probability of true physics trajectories, akin to learning a score function as Hyvärinen (2005) defined. By recursively applying the correction, they can invert longer temporal sequences, which corresponds to a probability flow (maximum likelihood) training perspective[\[16\]](https://arxiv.org/abs/2301.10250#:~:text=combining%20an%20approximate%20inverse%20physics,baselines%20for%20a%20wide%20range). The result is an inverse solver that is **accurate, temporally stable**, and importantly can sample the *posterior* distribution of solutions[\[17\]](https://arxiv.org/abs/2301.10250#:~:text=with%20a%20single,the%20posterior%20of%20the%20solutions). This means instead of outputting just one possible solution, the method can generate an ensemble of plausible solutions consistent with the observations, capturing uncertainty.

   * **Relation to fluid dynamics:** Many fluid mechanics problems are inverse in nature (e.g., flow control: deducing what boundary conditions caused an observed flow; or inferring missing flow regions from sparse sensor data). This work demonstrates that diffusion models (through score matching) are not only good for forward generative tasks but also excel at these inverse tasks. The ability to sample the posterior is particularly relevant for fluids under uncertainty – rather than a single guess of the flow, one might need a distribution of flows that could all agree with observed data (think of weather prediction, where multiple scenarios are possible). Holzschuh et al.’s solver provides exactly that, leveraging the probabilistic framework of diffusion models to quantify uncertainty in inverse solutions.

   * **Links to other works:** This approach builds directly on Hyvärinen’s theory (they explicitly connect single-step training to Hyvärinen’s score matching objective) and on score-based generative modeling techniques. It parallels image inpainting methods like RePaint, but in a physics context: both involve “filling in” missing information (RePaint fills missing pixels; Holzschuh et al. fill missing pieces of a physics trajectory). Additionally, the concept of combining a physics-based model with a learned generative model foreshadows hybrid approaches in simulation – for example, one might imagine using a quick physics approximation for an airflow and then a diffusion model to add realistic turbulence on top. By showing the strength of score-based learning in physics, this work paves the way for others (like Shu et al. 2023 or Liu & Thuerey 2024\) to trust diffusion models in scientific applications and to design algorithms that output not just predictions but distributions.

9. **Shu et al. (2023)** – *A Physics-Informed Diffusion Model for High-Fidelity Flow Field Reconstruction.* Dule Shu and colleagues developed a diffusion-based approach to **reconstruct high-resolution flow fields** from limited or lower-quality data[\[18\]](https://arxiv.org/abs/2211.14680#:~:text=diffusion%20model%20which%20only%20uses,different%20input%20sources%20without%20retraining). The paper targets the problem of super-resolution or data enhancement in fluids: for instance, taking a coarse CFD simulation or a sparse set of sensor measurements and reconstructing the detailed, high-fidelity flow. Unlike many existing models that require paired low- and high-fidelity data for training, Shu et al.’s diffusion model is trained *only on high-fidelity simulations*. During inference, it can be applied in two modes: (a) condition on a low-fidelity flow solution to produce a refined high-fidelity version, or (b) condition on sparse partial observations to fill in the full field[\[18\]](https://arxiv.org/abs/2211.14680#:~:text=diffusion%20model%20which%20only%20uses,different%20input%20sources%20without%20retraining). Because it was trained purely on high-res data, it doesn’t depend on the specifics of how low-res data look, making it generalizable to various types of inputs. A key feature is that the model is **physics-informed**: when additional information from the governing PDE (Navier-Stokes) is available, they incorporate it as conditioning to guide the diffusion process[\[18\]](https://arxiv.org/abs/2211.14680#:~:text=diffusion%20model%20which%20only%20uses,different%20input%20sources%20without%20retraining). For example, one could supply a physically derived intermediate field or enforce physical constraints during denoising. This conditioning helps ensure that the reconstructed flow is not only visually plausible but also adheres to physics (e.g., satisfying incompressibility). **Results:** The model successfully produced accurate reconstructions of 2D turbulent flow fields, demonstrating it can add the missing high-frequency vortex details and correct structures that a low-fidelity solver might miss[\[19\]](https://arxiv.org/abs/2211.14680#:~:text=a%20regular%20low,different%20input%20sources%20without%20retraining). It worked across different scenarios (different types of input degradation) *without retraining*, highlighting its robustness.

   * **Relation to fluid dynamics:** High-fidelity data is expensive in CFD, so this approach serves as a **surrogate to up-sample or enhance simulations**. From a diffusion model sampling perspective, Shu et al. show that you can leverage the *iterative refinement* nature of diffusion models to incorporate physics knowledge: at each denoising step, the model can be nudged by physics (like nudging it towards satisfying a pressure Poisson equation, for instance). This is a direct improvement of sampling for fluid problems – it’s no longer blind denoising, but *informed denoising*. The result is faster and more accurate generation of physically consistent fluid fields than naive generative models.

   * **Links to other works:** Shu et al.’s work is part of a growing trend of **physics-informed machine learning**. It relates to others like Lippe et al. (2023) and Liu & Thuerey (2024) in the sense that all infuse physical constraints or insights into diffusion models. Specifically, it complements works like Yang & Sommer (2023): while Yang & Sommer predict the next state with a diffusion model (time evolution), Shu et al. focus on improving the *spatial quality* of each state. In practice, these ideas could combine – one could imagine an autoregressive simulator (like Kohl 2024’s) that at each step uses a physics-informed diffusion refinement to maintain high fidelity. Overall, this paper underscores that diffusion models can be more than black-box generative tools; they can seamlessly integrate scientific knowledge for superior performance.

10. **Yang and Sommer (2023)** – *A Denoising Diffusion Model for Fluid Field Prediction.* Gefan Yang and Stefan Sommer introduced **FluidDiff**, one of the earliest applications of diffusion models to *forward* fluid simulation (predicting how a fluid field evolves)[\[20\]](https://arxiv.org/abs/2301.11661#:~:text=,system%2C%20it%20shares%20competitive%20performance). Their model is trained on simulated fluid dynamics data (e.g., 2D turbulent flows) and learns to model the distribution of flow states. Given an initial fluid state, FluidDiff uses a **Langevin dynamics sampling procedure** (essentially iterative noising and denoising) to generate the next states of the fluid[\[20\]](https://arxiv.org/abs/2301.11661#:~:text=,system%2C%20it%20shares%20competitive%20performance). Over many time steps, this produces a trajectory of the fluid flow. The main point is that instead of predicting the next state in one deterministic step (as in traditional neural PDE solvers), they add random noise and then denoise, which helps maintain stability and account for uncertainty. **Findings:** FluidDiff was able to simulate the fluid forwards in time with accuracy comparable to other deep learning approaches, and it exhibited strong **temporal stability** – meaning the generated flows did not diverge or explode even over long rollouts[\[21\]](https://arxiv.org/abs/2301.11661#:~:text=trained%20with%20finite%2C%20discrete%20fluid,new%20computational%20fluid%20dynamics%20methods). Notably, the model achieved this without explicitly encoding the physics equations; it was a purely data-driven approach, yet it could handle the nonlinear, multi-scale nature of turbulent dynamics. The stochastic sampling also means the model can produce *different plausible outcomes* if run multiple times, reflecting the chaotic nature of some flows.

    * **Relation to fluid dynamics:** This work demonstrated the viability of **autoregressive diffusion models** for fluid simulations. One big motivation for using diffusion in time-evolving systems is the issue of error accumulation: traditional neural nets, if slightly wrong at each step, compound errors and often become unstable. Yang & Sommer showed that the diffusion model’s probabilistic iterative approach inherently mitigates this – essentially by re-introducing random perturbations and correcting them, it avoids drifting too far off physically valid states. This is a crucial improvement in sampling for long-term fluid predictions.

    * **Links to other works:** Yang & Sommer (2023) appears to be one of the pioneering efforts that inspired further research like Kohl et al. (2024) and Lippe et al. (2023). In the introduction of the primary paper, it’s cited as an example of 2D autoregressive sampling with diffusion. Compared to physics-informed approaches (like Shu et al. 2023), FluidDiff is *less constrained* (no explicit Navier-Stokes enforcement) but still performed well – illustrating that even vanilla diffusion can capture a lot of physics. Its success is in line with observations by Kohl (2024) that diffusion models are “unconditionally stable” for very long rollouts. In summary, Yang & Sommer opened the door to treating fluid simulation trajectories like “generative video modeling” problems, confirming that the strengths of diffusion models (stability, probabilistic outputs) can translate into the fluid mechanics realm.

11. **Lippe et al. (2023)** – *PDE-Refiner: Accurate Long Rollouts with Neural PDE Solvers.* Phillip Lippe and colleagues tackled the challenge of **long-term accuracy in neural network-based PDE simulations** by introducing PDE-Refiner, a method that blends ideas from diffusion models into neural solvers for time-dependent PDEs[\[22\]](https://arxiv.org/abs/2308.05732#:~:text=advances%20in%20diffusion%20models%20to,efficient%20assessment%20of%20the%20model%27s). They observed that many learned simulators struggle with high-frequency details and gradually accumulate error, leading to blow-ups or dissipation of important structures over long times. PDE-Refiner’s solution is to perform a **multi-step refinement at each time step** rather than a single prediction. Specifically, given a predicted next state (from a coarse neural solver or even from the same network’s first guess), they run a *denoising diffusion-like process* that iteratively improves this prediction[\[22\]](https://arxiv.org/abs/2308.05732#:~:text=advances%20in%20diffusion%20models%20to,efficient%20assessment%20of%20the%20model%27s). This refinement process allows the model to capture *all scales of information*: early refinement steps correct large, low-frequency errors, and later steps add fine details (much as diffusion models first outline a structure and then add high-frequency texture)[\[22\]](https://arxiv.org/abs/2308.05732#:~:text=advances%20in%20diffusion%20models%20to,efficient%20assessment%20of%20the%20model%27s). As a result, PDE-Refiner was able to produce **stable and accurate rollouts far longer** than other methods on challenging fluid dynamics benchmarks[\[23\]](https://arxiv.org/abs/2308.05732#:~:text=refinement%20process.%20We%20validate%20PDE,estimate%20when%20the%20surrogate%20becomes). It outperformed standard neural operators and even some classic numerical integrators in preserving quantities like energy spectrum over time. Another benefit noted is that because PDE-Refiner essentially samples from a distribution at each step (rather than giving a fixed output), one can estimate **uncertainty** or confidence by seeing how much the refined solutions vary – if the refinement converges tightly, the prediction is confident; if multiple refinements lead to different plausible outcomes, one knows the system might be unpredictable beyond that point[\[24\]](https://arxiv.org/abs/2308.05732#:~:text=outperform%20state,estimate%20when%20the%20surrogate%20becomes).

    * **Relation to fluid dynamics:** PDE-Refiner is directly aimed at improving diffusion model *sampling efficiency* for fluids. It takes the brute-force diffusion idea (which might normally require, say, 50 steps to get a good next state) and embeds it into a smarter process where a neural net provides an initial guess and the diffusion-style refinement only has to correct the errors of that guess. This way, the number of refinement iterations can be much smaller than generating a frame purely from noise. In essence, it’s a hybrid between one-step prediction and full diffusion – trading a bit more computation per step for a **dramatic gain in long-term stability**. For fluid simulations, this is a big deal: it means neural surrogates don’t necessarily have to choose between speed (single-step models) and accuracy (diffusion models with many steps); a middle ground can give the best of both.

    * **Links to other works:** PDE-Refiner draws inspiration from **consistency and distillation models** in generative modeling which also aim to reduce the steps needed. It also aligns with the theme of the primary paper, which proposes truncated diffusion processes to speed up inference. Conceptually, PDE-Refiner is quite similar to what the primary paper calls “Iterative Refinement” – both treat the generative update as solving a correction in a few stochastic iterations. Additionally, PDE-Refiner’s success on fluid benchmarks likely informed and encouraged subsequent works like Kohl et al. (2024) to include diffusion models in their comparisons. Overall, Lippe et al. demonstrated a practical pathway to harness diffusion models for **long-term predictions** without incurring the typical huge cost in sampling steps, which is precisely the kind of advancement needed to make diffusion-based fluid simulators more viable in real-world scenarios.

12. **Kohl et al. (2024)** – *Benchmarking Autoregressive Conditional Diffusion Models for Turbulent Flow Simulation.* Georg Kohl and colleagues performed an in-depth study evaluating diffusion models as surrogates for simulating turbulent flows. They focused on **autoregressive conditional diffusion models**, meaning the diffusion model predicts the flow at the next time step given the current state (and possibly given external parameters like boundary conditions or Reynolds number)[\[25\]](https://arxiv.org/abs/2309.01745#:~:text=relevance,find%20that%20even%20simple%20diffusion). The paper’s contributions are largely empirical: they introduce several challenging 2D flow test cases – including incompressible fluid flow past objects and compressible (transonic) flows, as well as homogeneous turbulence – and benchmark the diffusion-based solver against other approaches (like recurrent neural nets, UNet-based predictors, and even traditional CFD in some cases)[\[26\]](https://arxiv.org/abs/2309.01745#:~:text=generalize%20to%20flow%20parameters%20beyond,approaches%20allows%20for%20inferring%20multiple). Key findings from their benchmark include: (a) Diffusion models can **generalize** to flow conditions (e.g., different Reynolds numbers or object shapes) outside the training distribution better than many deterministic models[\[26\]](https://arxiv.org/abs/2309.01745#:~:text=generalize%20to%20flow%20parameters%20beyond,approaches%20allows%20for%20inferring%20multiple). (b) Even a relatively simple conditional diffusion approach achieved lower error and much better **temporal stability** over long rollouts compared to baseline neural simulators, which often suffered from blow-ups or loss of important flow features[\[27\]](https://arxiv.org/abs/2309.01745#:~:text=three%20challenging%202D%20scenarios%20including,Overall). (c) The probabilistic nature of the diffusion model is a strength in that it produces a distribution of outcomes; in their turbulence cases, the diffusion model’s samples captured the statistical properties of the flow (like the distribution of vorticity or energy spectrum) more faithfully than single-point predictions[\[28\]](https://arxiv.org/abs/2309.01745#:~:text=based%20approaches%20can%20outperform%20multiple,Overall). However, they also note (d) the **computational cost**: diffusion models require many iterations per time step, so while they narrow the accuracy gap with traditional solvers, they are slower at inference than feed-forward neural nets (though still much faster than full high-fidelity CFD)[\[29\]](https://arxiv.org/abs/2309.01745#:~:text=based%20approaches%20can%20outperform%20multiple,of%20inference%20speed%2C%20however%2C%20the).

    * **Relation to fluid dynamics:** This benchmark essentially validates diffusion models as a serious tool for fluid simulation. Prior to this, diffusion models were proven in computer vision, but less so in scientific computing. Kohl et al. provide evidence that, for flows with complex, chaotic dynamics, the extra effort of diffusion probabilistic sampling pays off in stability and accuracy. From the perspective of *improving sampling*, their work highlights where diffusion models shine and where they need improvement: they shine in *quality of results* (learning all modes of the flow, long-term consistency) and need improvement in *speed*. This directly motivates research like the primary paper’s, which aims to **reduce the number of function evaluations** (sampling steps) needed by diffusion models.

    * **Links to other works:** Kohl et al. build upon earlier 2D works (like Yang & Sommer 2023\) and are a counterpart to Lienen et al. (2024) which tackled 3D flows. In fact, Kohl’s “Tra” and “Fturb” test cases (mentioned in the primary paper) became standard benchmarks – the primary paper thanks Kohl for providing those and then shows improvements on them. Additionally, Kohl’s observation that diffusion models naturally handle *uncertainty and multi-modality* in fluid flows is echoed by Liu & Thuerey (2024) who explicitly design a diffusion surrogate to quantify uncertainty. In summary, this reference provides a **baseline assessment**: diffusion models are effective for turbulent flow simulation, and the remaining challenge is mainly to make them faster – setting the stage for innovations like truncated diffusion sampling or improved solvers.

13. **Lienen et al. (2024)** – *From Zero to Turbulence: Generative Modeling for 3D Flow Simulation.* Marten Lienen and colleagues took a novel view of fluid simulation by using **generative diffusion models to directly produce 3D turbulent flow fields**, without a traditional time-stepping procedure[\[30\]](https://arxiv.org/pdf/2306.01776#:~:text=the%20first%20place,our%20generative%20model%20captures%20the). They argue that for fully developed turbulence, one can bypass simulating the entire transient: instead of starting from a simple initial condition and running a solver until turbulence emerges, train a model to *generate a physically realistic turbulent state in one go*. The paper’s main contributions are: (a) A high-resolution 3D turbulence dataset with various objects (obstacles) in the flow, which they use to train the model on many examples of possible turbulent wake flows[\[31\]](https://arxiv.org/pdf/2306.01776#:~:text=states%20without%20relying%20on%20any,quality). (b) A diffusion model architecture called **TurbDiff** based on a 3D UNet, capable of generating vector flow fields on a grid. They incorporate boundary conditions (like the object shape) by treating it similarly to an image inpainting problem – i.e. the region of the solid object is “masked” in the grid and kept at known values (like zero velocity inside the object) while the diffusion model fills in the fluid region around it[\[32\]](https://arxiv.org/pdf/2306.01776#:~:text=Sohl,2023%3B%20L%C3%BCdke). They cite using a method akin to Lugmayr’s RePaint to achieve this[\[33\]](https://arxiv.org/pdf/2306.01776#:~:text=match%20at%20L403%20We%20adapt,conditions%20fix%20the%20value%20of). (c) New evaluation metrics for generated turbulence, since classical pixel-wise error isn’t sufficient – they introduce metrics related to physical characteristics (perhaps energy spectra or vortex statistics) to assess if the generated flows *look like* real turbulence. **Findings:** The generative model was able to **capture the distribution of turbulent flows**: flows generated for unseen object shapes had realistic vortex structures and statistically matched the properties of the training data[\[34\]](https://arxiv.org/pdf/2306.01776#:~:text=challenging%203D%20turbulence%20dataset%20of,without%20access%20to%20any%20initial). Downstream tasks (like predicting lift and drag on the objects, or providing initial fields for simulations) confirmed that the samples were not just visually plausible but also physically meaningful. Essentially, given just an object’s shape and flow parameters, their diffusion model can “imagine” a plausible turbulent flow field around it, eliminating the need to simulate from scratch.

    * **Relation to fluid dynamics:** This work represents a different way to use diffusion models for fluids – not for stepping through time, but for directly sampling from the *steady-state distribution* of a chaotic system. This is particularly useful for design tasks (e.g., quickly generating possible airflow patterns around a car for many designs) or uncertainty studies (producing many realizations of a turbulent flow to see variability). In terms of sampling improvement, since they generate in one shot, they avoid the accumulation of error over time altogether. The challenge they address is ensuring **physical constraint satisfaction** (hence the boundary conditioning) and capturing 3D structures, which is computationally heavy. They do mention that generative diffusion in 3D is expensive, and they allude to the need for faster sampling or distillation techniques[\[35\]](https://arxiv.org/pdf/2306.01776#:~:text=is%20that%20generative%20diffusion%20is,2022), similar to 2D cases.

    * **Links to other works:** Lienen et al. connects to Lugmayr et al. (inpainting for boundaries) and to the general diffusion model literature (they base on Ho et al. 2020 and adapt it[\[36\]](https://arxiv.org/pdf/2306.01776#:~:text=We%20base%20our%20model%20TurbDiff,2023%3B%20L%C3%BCdke)). It stands in contrast to Kohl et al. (2024) – *autoregressive vs. one-shot:* Kohl simulates the process, Lienen generates the outcome distribution directly. Interestingly, both approaches are complementary: Kohl’s model might be better if you need the *transient evolution*, whereas Lienen’s is optimized for the *end state*. In practice, a fluid engineer might use Lienen’s model to generate a bunch of possible end states of a turbulent flow (very fast), then use a few diffusion time steps (like a short conditional simulation) to refine or adjust if needed – merging the ideas. For the diffusion community, this work is a milestone showing that **diffusion models can handle extremely high-dimensional outputs (3D fields)** and still respect complex constraints, as long as the architecture and conditioning are designed well. It underscores the flexibility of diffusion models: whether one needs a full time-course (like a video) or just a random sample from a complicated steady distribution, the same principles apply.

14. **Liu and Thuerey (2024)** – *Uncertainty-Aware Surrogate Models for Airfoil Flows with DDPMs.* Qiang Liu and Nils Thuerey developed a diffusion-model-based surrogate for simulating airflow around airfoils (wing cross-sections) that not only predicts the flow field but also quantifies the **uncertainty** in those predictions[\[37\]](https://arxiv.org/abs/2312.05320#:~:text=remains%20very%20challenging,Experiments%20demonstrate)[\[38\]](https://arxiv.org/abs/2312.05320#:~:text=DDPMs%20can%20successfully%20capture%20the,emerging%20generative%20modeling%20variant%2C%20flow). In aerodynamics, variations in conditions or slight differences in geometry can lead to different flow outcomes, so being able to model a distribution of possible flows (rather than a single deterministic flow) is valuable. The authors trained a conditional DDPM on a dataset of airfoil flows spanning a range of shapes, angles of attack, and Reynolds numbers[\[39\]](https://arxiv.org/abs/2312.05320#:~:text=surrogate%20model%20for%20turbulence%20simulations,a%20variety%20of%20accuracy%20metrics). The diffusion model takes as input the airfoil parameters and produces a sample of the flow (velocity and pressure fields) around that airfoil. Because it’s probabilistic, one can draw many samples for the same conditions to see the range of possible outcomes (which might correspond, for example, to different possible onset turbulence patterns or uncertainties in inflow conditions). **Main findings:** The DDPM surrogate **successfully learned the entire distribution** of steady-state flow solutions for given conditions – when compared to high-fidelity simulation data, the generated samples covered the variability seen in real simulations[\[40\]](https://arxiv.org/abs/2312.05320#:~:text=simulation%20of%20flows%20around%20airfoils,As). In terms of point accuracy, their method outperformed baseline approaches like Bayesian neural networks or deterministic neural nets with predictive variance, meaning it was more precise *and* more informative[\[38\]](https://arxiv.org/abs/2312.05320#:~:text=DDPMs%20can%20successfully%20capture%20the,emerging%20generative%20modeling%20variant%2C%20flow). Not only can it provide mean and variance predictions, but it can output full field samples that align with those uncertainty estimates (e.g., regions of high output variability in the samples correspond to where the flow is known to be uncertain or sensitive). Additionally, recognizing the slow sampling issue of diffusion models, they experimented with an alternative called **flow matching** to accelerate inference[\[41\]](https://arxiv.org/abs/2312.05320#:~:text=solutions,uncertainty%20quantification%20with%20generative%20models). Flow matching is a technique to train a model to generate samples in fewer steps (essentially by learning an ODE that transports samples according to the probability flow). They found that flow matching indeed **speeded up generation** notably while still maintaining good uncertainty quantification[\[41\]](https://arxiv.org/abs/2312.05320#:~:text=solutions,uncertainty%20quantification%20with%20generative%20models).

    * **Relation to fluid dynamics:** This work directly addresses a major advantage of diffusion models – their ability to capture uncertainty – in a practical engineering context. Airfoil performance can depend on unpredictable factors (like slight turbulence in incoming air), and a traditional surrogate model might give you a single average pressure distribution. In contrast, a diffusion-based surrogate can give you a family of possible pressure distributions, from which you could estimate, say, a confidence interval for lift or identify probabilities of flow separation. This is a compelling improvement for risk-aware design and analysis. From the sampling perspective, Liu & Thuerey demonstrate how one can maintain the benefits of diffusion models while mitigating their biggest drawback (slow sampling) by using advanced training methods (flow matching). It shows that **improving sampling efficiency** doesn’t necessarily sacrifice the uncertainty modeling capability – in fact, they highlight flow matching as a promising direction to get “the best of both worlds”[\[41\]](https://arxiv.org/abs/2312.05320#:~:text=solutions,uncertainty%20quantification%20with%20generative%20models).

    * **Links to other works:** This paper is a culmination of several threads: it cites works like Holzschuh et al. (using score-based methods in physics) and Kohl et al. (the “Air” benchmark case is an airfoil flow, and Liu & Thuerey’s method is an improved surrogate for that). It also resonates with Dhariwal & Nichol (2021) in the sense of exploring ways to reduce steps (just as Dhariwal & Nichol tried fewer diffusion steps and guided sampling, Liu & Thuerey try flow matching as a form of model distillation for faster sampling). Conceptually, it aligns with the whole push in the diffusion community to marry **quality with speed**. For the fluid community, it’s one of the first to explicitly bring uncertainty quantification to the forefront using generative models. We see similar spirit in Holzschuh et al. (sampling the posterior for inversions) and in the argument by Kohl et al. that diffusion models naturally give multiple outcomes. Liu & Thuerey package that into an application-driven paper, likely making a case to the CFD community (via AIAA Journal) that these modern AI techniques can tackle not just predictions but also confidence – a critical aspect for engineering decision-making.

---

[\[1\]](https://jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf#:~:text=Here%2C%20we%20propose%20that%20such,The%20density) jmlr.org

[https://jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf](https://jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf)

[\[2\]](https://arxiv.org/abs/1503.03585#:~:text=achieves%20both%20flexibility%20and%20tractability,reference%20implementation%20of%20the%20algorithm) \[1503.03585\] Deep Unsupervised Learning using Nonequilibrium Thermodynamics

[https://arxiv.org/abs/1503.03585](https://arxiv.org/abs/1503.03585)

[\[3\]](https://arxiv.org/abs/2105.05233#:~:text=,guidance%20combines%20well%20with%20upsampling) [\[4\]](https://arxiv.org/abs/2105.05233#:~:text=superior%20to%20the%20current%20state,guidance%20combines%20well%20with%20upsampling) [\[5\]](https://arxiv.org/abs/2105.05233#:~:text=of%20ablations,at%20%2013%20this%20https) \[2105.05233\] Diffusion Models Beat GANs on Image Synthesis

[https://arxiv.org/abs/2105.05233](https://arxiv.org/abs/2105.05233)

[\[6\]](https://www.researchgate.net/publication/358143708_RePaint_Inpainting_using_Denoising_Diffusion_Probabilistic_Models#:~:text=,) RePaint: Inpainting using Denoising Diffusion Probabilistic Models | Request PDF

[https://www.researchgate.net/publication/358143708\_RePaint\_Inpainting\_using\_Denoising\_Diffusion\_Probabilistic\_Models](https://www.researchgate.net/publication/358143708_RePaint_Inpainting_using_Denoising_Diffusion_Probabilistic_Models)

[\[7\]](https://arxiv.org/abs/2204.03458#:~:text=,We%20present%20the) [\[8\]](https://arxiv.org/abs/2204.03458#:~:text=milestone%20by%20proposing%20a%20diffusion,generation%20task%2C%20as%20well%20as) [\[9\]](https://arxiv.org/abs/2204.03458#:~:text=image%20diffusion%20architecture%2C%20and%20it,available%20at%20this%20https%20URL) \[2204.03458\] Video Diffusion Models

[https://arxiv.org/abs/2204.03458](https://arxiv.org/abs/2204.03458)

[\[10\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=review%20the%20recent%20progress%20in,and%20introduce%20optimization%20techniques%20for) [\[11\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=e.g.%2C%20knowledge%20distillation%20,the%20intermediate%20generated%20results%20conditioned) [\[12\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=generation%20quality%2C%20leading%20to%20an,the%20discrete%20essence%20and%20complex) [\[13\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=present%20the%20general%20defnition%20of,Our%20survey) [\[14\]](https://www.ijcai.org/proceedings/2023/0750.pdf#:~:text=progressively%20convert%20a%20random%20noise,to%20an%20improved%20generation%20ability) Diffusion Models for Non-autoregressive Text Generation: A Survey

[https://www.ijcai.org/proceedings/2023/0750.pdf](https://www.ijcai.org/proceedings/2023/0750.pdf)

[\[15\]](https://arxiv.org/abs/2301.10250#:~:text=combining%20an%20approximate%20inverse%20physics,contrast%20to%20other%20learned%20inverse) [\[16\]](https://arxiv.org/abs/2301.10250#:~:text=combining%20an%20approximate%20inverse%20physics,baselines%20for%20a%20wide%20range) [\[17\]](https://arxiv.org/abs/2301.10250#:~:text=with%20a%20single,the%20posterior%20of%20the%20solutions) \[2301.10250\] Solving Inverse Physics Problems with Score Matching

[https://arxiv.org/abs/2301.10250](https://arxiv.org/abs/2301.10250)

[\[18\]](https://arxiv.org/abs/2211.14680#:~:text=diffusion%20model%20which%20only%20uses,different%20input%20sources%20without%20retraining) [\[19\]](https://arxiv.org/abs/2211.14680#:~:text=a%20regular%20low,different%20input%20sources%20without%20retraining) \[2211.14680\] A Physics-informed Diffusion Model for High-fidelity Flow Field Reconstruction

[https://arxiv.org/abs/2211.14680](https://arxiv.org/abs/2211.14680)

[\[20\]](https://arxiv.org/abs/2301.11661#:~:text=,system%2C%20it%20shares%20competitive%20performance) [\[21\]](https://arxiv.org/abs/2301.11661#:~:text=trained%20with%20finite%2C%20discrete%20fluid,new%20computational%20fluid%20dynamics%20methods) \[2301.11661\] A Denoising Diffusion Model for Fluid Field Prediction

[https://arxiv.org/abs/2301.11661](https://arxiv.org/abs/2301.11661)

[\[22\]](https://arxiv.org/abs/2308.05732#:~:text=advances%20in%20diffusion%20models%20to,efficient%20assessment%20of%20the%20model%27s) [\[23\]](https://arxiv.org/abs/2308.05732#:~:text=refinement%20process.%20We%20validate%20PDE,estimate%20when%20the%20surrogate%20becomes) [\[24\]](https://arxiv.org/abs/2308.05732#:~:text=outperform%20state,estimate%20when%20the%20surrogate%20becomes) \[2308.05732\] PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers

[https://arxiv.org/abs/2308.05732](https://arxiv.org/abs/2308.05732)

[\[25\]](https://arxiv.org/abs/2309.01745#:~:text=relevance,find%20that%20even%20simple%20diffusion) [\[26\]](https://arxiv.org/abs/2309.01745#:~:text=generalize%20to%20flow%20parameters%20beyond,approaches%20allows%20for%20inferring%20multiple) [\[27\]](https://arxiv.org/abs/2309.01745#:~:text=three%20challenging%202D%20scenarios%20including,Overall) [\[28\]](https://arxiv.org/abs/2309.01745#:~:text=based%20approaches%20can%20outperform%20multiple,Overall) [\[29\]](https://arxiv.org/abs/2309.01745#:~:text=based%20approaches%20can%20outperform%20multiple,of%20inference%20speed%2C%20however%2C%20the) \[2309.01745\] Benchmarking Autoregressive Conditional Diffusion Models for Turbulent Flow Simulation

[https://arxiv.org/abs/2309.01745](https://arxiv.org/abs/2309.01745)

[\[30\]](https://arxiv.org/pdf/2306.01776#:~:text=the%20first%20place,our%20generative%20model%20captures%20the) [\[31\]](https://arxiv.org/pdf/2306.01776#:~:text=states%20without%20relying%20on%20any,quality) [\[32\]](https://arxiv.org/pdf/2306.01776#:~:text=Sohl,2023%3B%20L%C3%BCdke) [\[33\]](https://arxiv.org/pdf/2306.01776#:~:text=match%20at%20L403%20We%20adapt,conditions%20fix%20the%20value%20of) [\[34\]](https://arxiv.org/pdf/2306.01776#:~:text=challenging%203D%20turbulence%20dataset%20of,without%20access%20to%20any%20initial) [\[35\]](https://arxiv.org/pdf/2306.01776#:~:text=is%20that%20generative%20diffusion%20is,2022) [\[36\]](https://arxiv.org/pdf/2306.01776#:~:text=We%20base%20our%20model%20TurbDiff,2023%3B%20L%C3%BCdke) From Zero to Turbulence: Generative Modeling for 3D Flow Simulation

[https://arxiv.org/pdf/2306.01776](https://arxiv.org/pdf/2306.01776)

[\[37\]](https://arxiv.org/abs/2312.05320#:~:text=remains%20very%20challenging,Experiments%20demonstrate) [\[38\]](https://arxiv.org/abs/2312.05320#:~:text=DDPMs%20can%20successfully%20capture%20the,emerging%20generative%20modeling%20variant%2C%20flow) [\[39\]](https://arxiv.org/abs/2312.05320#:~:text=surrogate%20model%20for%20turbulence%20simulations,a%20variety%20of%20accuracy%20metrics) [\[40\]](https://arxiv.org/abs/2312.05320#:~:text=simulation%20of%20flows%20around%20airfoils,As) [\[41\]](https://arxiv.org/abs/2312.05320#:~:text=solutions,uncertainty%20quantification%20with%20generative%20models) \[2312.05320\] Uncertainty-aware Surrogate Models for Airfoil Flow Simulations with Denoising Diffusion Probabilistic Models

[https://arxiv.org/abs/2312.05320](https://arxiv.org/abs/2312.05320)